# Example on how the training config file could look like 
define: &num_classes 37
define: &input_size [480, 480]
define: &padding_color [114, 114, 114]
define: &color_mean [103.53, 116.28, 123.675]
define: &color_std [57.375, 57.12, 58.395]
define: &batch_size 128

train_config:
  model_cfg:
    model_name: "RTMDetTiny"
    num_classes: *num_classes 
    model_weights: model_weights/RTMDetTiny-coco.pth
    strict: false

  training_dataloader_config:
    dataset_configs:
      - name: "OxfordPetDataset"
        config:
          annotations_file_path: data/annotations/train.yaml
          image_dir_path: data/images
          preprocessor_config:
            dest_size: *input_size
            pad_color: *padding_color
            mean: *color_mean
            std: *color_std
          num_classes: *num_classes
    batch_size: *batch_size
  
  validation_dataloader_config:
    dataset_configs:
      - name: "OxfordPetDataset"
        config:
          annotations_file_path: data/annotations/valid.yaml
          image_dir_path: data/images
          preprocessor_config:
            dest_size: *input_size
            pad_color: *padding_color
            mean: *color_mean
            std: *color_std
          num_classes: *num_classes
          augment: false
    batch_size: *batch_size
  
  loss_fn_config:
    name: "RTMDetLoss"
    config: 
      reg_loss_weight: 2
  
  optimizer_config:
    name: "AdamW"
    config:
      lr: 0.001
      weight_decay: 0.05

  lr_scheduler_config:
    name: CosineAnnealingLR
    config:
      T_max: 80
      eta_min: 0.0001
  ema_decay: 0.9

  session_name: "test"
  weights_save_path: model_weights/trained
  epochs: 80
  device: "cuda:0"